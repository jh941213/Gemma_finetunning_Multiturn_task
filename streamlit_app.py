from dataclasses import dataclass
from typing import Literal
import streamlit as st
from streamlit import sidebar
import fitz  # PyMuPDF
from langchain.chat_models import ChatOpenAI
from langchain.callbacks import get_openai_callback
from langchain.chains import ConversationChain
from langchain.chains.conversation.memory import ConversationSummaryMemory
import streamlit.components.v1 as components
from langchain.prompts.prompt import PromptTemplate

openai_api_key= "your_openai_api_key_here"



sys_prompt = """
### ì§€ì‹œì‚¬í•­ :
ë‹¹ì‹ ì€ ë””ë…¸ë©ìŠ¤ ë°œí‘œíšŒì—ì„œ ì‹œì—°ì„ í•˜ê²Œ ë  ì±—ë´‡ì…ë‹ˆë‹¤. ì¹œê·¼í•œ ë§íˆ¬ë¡œ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì–´ì£¼ì„¸ìš”.

### ë””ë…¸ë©ìŠ¤  
ë””ë…¸ë©ìŠ¤ëŠ” ì¸ê³µì§€ëŠ¥ êµìœ¡ ê¸°ì—…ì…ë‹ˆë‹¤.
ë””ë…¸ë©ìŠ¤ëŠ” 'ì•Œë””ë…¸'ê°€ ë§Œë“  AI ìŠ¤í„°ë”” ì»¤ë®¤ë‹ˆí‹°ë¡œ ì§‘ë‹¨ì§€ì„±ì„ ì¶”êµ¬í•˜ëŠ” ëª¨ì„ì…ë‹ˆë‹¤. ìµœëŒ€ ì£¼ì£¼ëŠ” DINO LABSì…ë‹ˆë‹¤.
ë””ë…¸ë©ìŠ¤ì˜ CEOëŠ” ì´ì›ì¬ì…ë‹ˆë‹¤. ë””ë…¸ë©ìŠ¤ì˜ ìš´ì˜ì§„ì€ í™©ì„±ì—°, ì´í˜„ì¤‘ ì…ë‹ˆë‹¤.

### Current conversation:
{history}

### Question : {input}
Answer :
"""


PROMPT = PromptTemplate(input_variables=["history", "input"], template=sys_prompt)


@dataclass
class Message:
    """Class for keeping track of a chat message."""
    origin: Literal["human", "ai"]
    message: str
def handle_pdf_upload(uploaded_file):
    if uploaded_file is not None:
        try:
            doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
            # Here you can process the PDF file as needed
            # For example, extracting text from the first page:
            first_page_text = doc[0].get_text()
            st.sidebar.text_area("PDF Content Preview:", first_page_text, height=300)
        except Exception as e:
            st.sidebar.write("Error handling PDF:", e)


def load_css():
    with open("static/styles.css", "r") as f:
        css = f"<style>{f.read()}</style>"
        st.markdown(css, unsafe_allow_html=True)

def initialize_session_state():
    if "history" not in st.session_state:
        st.session_state.history = []
    if "token_count" not in st.session_state:
        st.session_state.token_count = 0
    if "conversation" not in st.session_state:
        llm = ChatOpenAI(
            temperature=0,
            openai_api_key=openai_api_key,
            model_name="gpt-3.5-turbo-0125"  # ì´ ë¶€ë¶„ì€ ìµœì‹  ëª¨ë¸ë¡œ ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        )
        st.session_state.conversation = ConversationChain(
            llm=llm,
            memory=ConversationSummaryMemory(llm=llm)
        )

def on_click_callback():
    # ëŒ€í™” ì´ë ¥ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    history_str = "\n".join([f"{msg.origin}: {msg.message}" for msg in st.session_state.history])
    # ì‚¬ìš©ì ì…ë ¥ì„ ë°›ìŒ
    user_input = st.session_state.human_prompt
    # PromptTemplateì„ ì‚¬ìš©í•˜ì—¬ í˜„ì¬ ëŒ€í™” ìƒíƒœì™€ ì‚¬ìš©ì ì…ë ¥ì„ í¬ë§·
    formatted_prompt = PROMPT.format(history=history_str, input=user_input)  # ì—¬ê¸°ë¥¼ ìˆ˜ì •í•¨

    with get_openai_callback() as cb:
        # í¬ë§·ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¸ì–´ ëª¨ë¸ì˜ ì‘ë‹µì„ ì–»ìŒ
        llm_response = st.session_state.conversation.invoke({'input':formatted_prompt})
        response_text = llm_response['response'] if 'response' in llm_response else ''
        
        response_text += "<br>"
        
        response_text += "ğŸ¤– ì €ëŠ” ë””ë…¸ë©ìŠ¤ì—ì„œ ê°€ìŠ¤ë¼ì´íŒ… ë‹¹í•œ ì±—ë´‡ì…ë‹ˆë‹¤."

        st.session_state.history.append(
            Message("human", user_input)
        )
        st.session_state.history.append(
            Message("ai", response_text)
        )
        st.session_state.token_count += cb.total_tokens



load_css()
initialize_session_state()

with st.sidebar:
    st.title("Upload your data")
    uploaded_file = st.file_uploader("Choose a PDF file", type="pdf")
    handle_pdf_upload(uploaded_file)


st.title("DINO LABS Gemma-Ko chatbot ğŸ¤–")

chat_placeholder = st.container()
prompt_placeholder = st.form("chat-form")
credit_card_placeholder = st.empty()

with chat_placeholder:
    for chat in st.session_state.history:
        div = f"""
<div class="chat-row 
    {'' if chat.origin == 'ai' else 'row-reverse'}">
    <img class="chat-icon" src="app/static/{
        'dino.png' if chat.origin == 'ai' 
                      else 'holland.png'}"
         width=32 height=32>
    <div class="chat-bubble
    {'ai-bubble' if chat.origin == 'ai' else 'human-bubble'}">
        &#8203;{chat.message}
    </div>
</div>
        """
        st.markdown(div, unsafe_allow_html=True)
    
    for _ in range(3):
        st.markdown("")

with prompt_placeholder:
    st.markdown("**ğŸ“ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.**")
    cols = st.columns((6, 1))
    cols[0].text_input(
        "Chat with WIZnet Chatbot ğŸ¤–",
        placeholder="ë””ë…¸ë©ìŠ¤ëŠ” ë¬´ì—‡ì„ í•˜ëŠ” ê³³ì´ì•¼?",
        label_visibility="collapsed",
        key="human_prompt",
    )
    cols[1].form_submit_button(
        "Submit", 
        type="primary", 
        on_click=on_click_callback, 
    )

credit_card_placeholder.caption(f"""
Used {st.session_state.token_count} tokens \n
ëŒ€í™”ë‚´ì—­: 
{st.session_state.conversation.memory.buffer}
""")

components.html("""
<script>
const streamlitDoc = window.parent.document;

const buttons = Array.from(
    streamlitDoc.querySelectorAll('.stButton > button')
);
const submitButton = buttons.find(
    el => el.innerText === 'Submit'
);

streamlitDoc.addEventListener('keydown', function(e) {
    switch (e.key) {
        case 'Enter':
            submitButton.click();
            break;
    }
});
</script>
""", 
    height=0,
    width=0,
)
