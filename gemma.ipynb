{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes==0.42.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from bitsandbytes==0.42.0) (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from scipy->bitsandbytes==0.42.0) (1.26.4)\n",
      "Collecting peft==0.8.2\n",
      "  Using cached peft-0.8.2-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from peft==0.8.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from peft==0.8.2) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from peft==0.8.2) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from peft==0.8.2) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from peft==0.8.2) (2.1.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from peft==0.8.2) (4.39.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from peft==0.8.2) (4.66.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from peft==0.8.2) (0.27.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from peft==0.8.2) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from peft==0.8.2) (0.21.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.13.0->peft==0.8.2) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.13.0->peft==0.8.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.13.0->peft==0.8.2) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from tqdm->peft==0.8.2) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers->peft==0.8.2) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers->peft==0.8.2) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from jinja2->torch>=1.13.0->peft==0.8.2) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hyun0\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from sympy->torch>=1.13.0->peft==0.8.2) (1.3.0)\n",
      "Using cached peft-0.8.2-py3-none-any.whl (183 kB)\n",
      "Installing collected packages: peft\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.10.0\n",
      "    Uninstalling peft-0.10.0:\n",
      "      Successfully uninstalled peft-0.10.0\n",
      "Successfully installed peft-0.8.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmtuner 0.6.1 requires accelerate>=0.27.2, but you have accelerate 0.27.1 which is incompatible.\n",
      "llmtuner 0.6.1 requires peft>=0.10.0, but you have peft 0.8.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trl==0.7.10\n",
      "  Using cached trl-0.7.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from trl==0.7.10) (2.1.1)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from trl==0.7.10) (4.39.1)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from trl==0.7.10) (1.26.4)\n",
      "Requirement already satisfied: accelerate in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from trl==0.7.10) (0.27.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from trl==0.7.10) (2.17.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from trl==0.7.10) (0.7.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.4.0->trl==0.7.10) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.4.0->trl==0.7.10) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.4.0->trl==0.7.10) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.4.0->trl==0.7.10) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.4.0->trl==0.7.10) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.4.0->trl==0.7.10) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.10) (0.21.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.10) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.10) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.10) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.10) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.10) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.10) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.10) (4.66.2)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.10) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.10) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.10) (1.7.1)\n",
      "Requirement already satisfied: colorama>=0.4.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.10) (0.4.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from accelerate->trl==0.7.10) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets->trl==0.7.10) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets->trl==0.7.10) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets->trl==0.7.10) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets->trl==0.7.10) (2.2.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets->trl==0.7.10) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets->trl==0.7.10) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets->trl==0.7.10) (3.9.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets->trl==0.7.10) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets->trl==0.7.10) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets->trl==0.7.10) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets->trl==0.7.10) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets->trl==0.7.10) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets->trl==0.7.10) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hyun0\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers>=4.31.0->trl==0.7.10) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->transformers>=4.31.0->trl==0.7.10) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->transformers>=4.31.0->trl==0.7.10) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->transformers>=4.31.0->trl==0.7.10) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from jinja2->torch>=1.4.0->trl==0.7.10) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from pandas->datasets->trl==0.7.10) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from pandas->datasets->trl==0.7.10) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from pandas->datasets->trl==0.7.10) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from sympy->torch>=1.4.0->trl==0.7.10) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.10) (1.16.0)\n",
      "Using cached trl-0.7.10-py3-none-any.whl (150 kB)\n",
      "Installing collected packages: trl\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.8.1\n",
      "    Uninstalling trl-0.8.1:\n",
      "      Successfully uninstalled trl-0.8.1\n",
      "Successfully installed trl-0.7.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmtuner 0.6.1 requires accelerate>=0.27.2, but you have accelerate 0.27.1 which is incompatible.\n",
      "llmtuner 0.6.1 requires peft>=0.10.0, but you have peft 0.8.2 which is incompatible.\n",
      "llmtuner 0.6.1 requires trl>=0.8.1, but you have trl 0.7.10 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate==0.27.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from accelerate==0.27.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from accelerate==0.27.1) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from accelerate==0.27.1) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from accelerate==0.27.1) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from accelerate==0.27.1) (2.1.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from accelerate==0.27.1) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from accelerate==0.27.1) (0.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.27.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.27.1) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.27.1) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.27.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.27.1) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from torch>=1.10.0->accelerate==0.27.1) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from huggingface-hub->accelerate==0.27.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from huggingface-hub->accelerate==0.27.1) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate==0.27.1) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.27.1) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hyun0\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub->accelerate==0.27.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.27.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.27.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.27.1) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate==0.27.1) (1.3.0)\n",
      "Collecting datasets==2.17.0\n",
      "  Downloading datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (4.66.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.17.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (0.21.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from datasets==2.17.0) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets==2.17.0) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hyun0\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.19.0->datasets==2.17.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from tqdm>=4.62.1->datasets==2.17.0) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from pandas->datasets==2.17.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from pandas->datasets==2.17.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from pandas->datasets==2.17.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.17.0) (1.16.0)\n",
      "Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.6/536.6 kB 35.1 MB/s eta 0:00:00\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.17.1\n",
      "    Uninstalling datasets-2.17.1:\n",
      "      Successfully uninstalled datasets-2.17.1\n",
      "Successfully installed datasets-2.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmtuner 0.6.1 requires accelerate>=0.27.2, but you have accelerate 0.27.1 which is incompatible.\n",
      "llmtuner 0.6.1 requires peft>=0.10.0, but you have peft 0.8.2 which is incompatible.\n",
      "llmtuner 0.6.1 requires trl>=0.8.1, but you have trl 0.7.10 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.38.1\n",
      "  Using cached transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers==4.38.1) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers==4.38.1) (0.21.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers==4.38.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers==4.38.1) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers==4.38.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers==4.38.1) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers==4.38.1) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers==4.38.1) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers==4.38.1) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from transformers==4.38.1) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.1) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.1) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from tqdm>=4.27->transformers==4.38.1) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hyun0\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers==4.38.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->transformers==4.38.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->transformers==4.38.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages (from requests->transformers==4.38.1) (2024.2.2)\n",
      "Using cached transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.39.1\n",
      "    Uninstalling transformers-4.39.1:\n",
      "      Successfully uninstalled transformers-4.39.1\n",
      "Successfully installed transformers-4.38.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmtuner 0.6.1 requires accelerate>=0.27.2, but you have accelerate 0.27.1 which is incompatible.\n",
      "llmtuner 0.6.1 requires peft>=0.10.0, but you have peft 0.8.2 which is incompatible.\n",
      "llmtuner 0.6.1 requires trl>=0.8.1, but you have trl 0.7.10 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install  -U bitsandbytes==0.42.0\n",
    "!pip install  -U peft==0.8.2\n",
    "!pip install  -U trl==0.7.10\n",
    "!pip install  -U accelerate==0.27.1\n",
    "!pip install  -U datasets==2.17.0\n",
    "!pip install  -U transformers==4.38.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "32e7669cd82042cbbb419e25db606c1d",
      "b6698be32bf74c4087e129fab6e13fdd",
      "ff7333b35c1c472482df6550f6e43be2",
      "da4df56a1ba440dbb69087d0019cab1d",
      "ad598693c58549e0a83a1328d77b8f83",
      "de2f7a60851f4681877a4c8dccba29cc",
      "02b296efbff143f4bfbb904cbc7b1109",
      "72ac83e43e2b4d4498070a5b701a5572",
      "320fa615d4de4652ac34fc2518f7749e",
      "75280ef205a245be92da268e0752dc71",
      "3f33eabd6f7f46ef8138abe748d8fbb1"
     ]
    },
    "id": "EVEotZX8s-v6",
    "outputId": "e378234f-f56f-483e-c569-f3a196c02370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin c:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121.dll\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:03<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch,os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GemmaTokenizer\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "\n",
    "model_id = \"beomi/gemma-ko-7b\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(        # 4-bit quantization\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_quant_type=\"nf8\",\n",
    "    bnb_8bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,padding_side = 'right')\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\",max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7lzjoG3KVRMN"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(      # lora configuration\n",
    "    r=8,\n",
    "    lora_alpha= 16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "# 데이터셋 불러오기\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"maywell/koVast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations'],\n",
       "        num_rows: 684579\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'user', 'value': '대학 입학 단계에서 의사소통 기회가 뭐야?'},\n",
       " {'from': 'gpt',\n",
       "  'value': '대학 입학 단계에서의 의사소통 기회는 대학과 연결하고 다양한 수준의 학업과 교육 활동에 참여하기 위해 제공되는 기회를 말합니다. 이는 대학에 입학하고 처음 대학 생활을 시작할 때 학생들이 대학 내에서 자신을 표현하고 다른 사람들과 소통하는 기회를 제공합니다.'},\n",
       " {'from': 'user', 'value': '그럼 이런 의사소통 기회를 잘 활용하려면 어떻게 해야 해?'},\n",
       " {'from': 'gpt',\n",
       "  'value': '이런 의사소통 기회를 잘 활용하기 위해서는 몇 가지 전략을 따르는 것이 좋습니다. 첫째, 강력하고 생산적인 관계를 형성하기 위해 대학 내에서 다양한 사람들과 교류하고 소통하는 것이 중요합니다. 둘째, 성공적인 대인관계를 위해서는 피드백을 제공하고 수락하는 것이 중요합니다. 이를 통해 서로의 의견을 이해하고 존중하며, 더 나은 관계를 형성할 수 있습니다.'},\n",
       " {'from': 'user', 'value': '전문적인 관점에서 소셜 미디어를 어떻게 활용해야 해?'},\n",
       " {'from': 'gpt',\n",
       "  'value': '전문적인 관점에서 소셜 미디어를 활용하기 위해서는 몇 가지 팁을 따르는 것이 좋습니다. 첫째, 자신의 전문적인 입장을 강화하기 위해 소셜 미디어를 적절히 사용하는 것이 중요합니다. 이는 자신의 전문 분야에 관련된 정보를 공유하고, 전문적인 토론에 참여하는 것을 의미합니다. 둘째, 소셜 미디어를 통해 학업, 교외 활동 및 일자리 기회를 탐색하는 데 도움이 되는 정보를 찾아보는 것도 유용합니다. 이를 통해 자신의 경력 발전에 도움이 될 수 있는 기회를 발견할 수 있습니다.'},\n",
       " {'from': 'user', 'value': '서면 의사소통의 중요성은 구체적으로 뭐야?'},\n",
       " {'from': 'gpt',\n",
       "  'value': '서면 의사소통의 중요성은 다양한 서신 및 문서를 만들고 수정하는 데 적절한 문법과 스타일을 활용하는 것에 있습니다. 이는 교과 과제, 논문, 책임 서류, 편지 등을 작성할 때 중요한 역할을 합니다. 서면 의사소통을 잘 하는 것은 커뮤니케이션 능력을 향상시키고, 다양한 상황에서 명확하고 효과적으로 메시지를 전달하는 데 도움이 됩니다. 이는 학업 성공뿐만 아니라 장기적인 경력 발전에도 중요한 요소입니다.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['conversations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhyun030508\u001b[0m (\u001b[33mkdbwandb\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\hyun0\\.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\hyun0\\OneDrive\\바탕 화면\\Gemma_finetunning_Multiturn_task-main\\wandb\\run-20240401_074036-r0x9cyy8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kdbwandb/gemma-ko-7b-multiturn/runs/r0x9cyy8/workspace' target=\"_blank\">radiant-donkey-3</a></strong> to <a href='https://wandb.ai/kdbwandb/gemma-ko-7b-multiturn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kdbwandb/gemma-ko-7b-multiturn' target=\"_blank\">https://wandb.ai/kdbwandb/gemma-ko-7b-multiturn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kdbwandb/gemma-ko-7b-multiturn/runs/r0x9cyy8/workspace' target=\"_blank\">https://wandb.ai/kdbwandb/gemma-ko-7b-multiturn/runs/r0x9cyy8/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "secret_wandb = \"155cbd25973f60b11ce57a095662e353e0cd6b80\"\n",
    "wandb.login(key = secret_wandb)\n",
    "run = wandb.init(\n",
    "    project='gemma-ko-7b-multiturn', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations'],\n",
       "        num_rows: 684579\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = \"gemma-ko-7b-multiturn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from trl import SFTTrainer,DataCollatorForCompletionOnlyLM\n",
    "\n",
    "def formatting_func(example): # example을 받아서 text로 변환\n",
    "    output_texts = []\n",
    "    for conversation in example['conversations']:\n",
    "        for i in range(len(conversation)):\n",
    "            if conversation[i]['from'] == 'user':\n",
    "                question = conversation[i]['value']\n",
    "                answer = conversation[i+1]['value'] if i+1 < len(conversation) and conversation[i+1]['from'] == 'gpt' else 'No answer'\n",
    "                text = f\"user: {question}\\n model: {answer}\"\n",
    "                output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "response_template = \"model:\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = Dataset.from_dict({\n",
    "    'conversations': dataset['train']['conversations'][:10000]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversations'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "HFbR2FIgVfiT",
    "outputId": "ba27fbda-54be-415c-ee47-78632e4ad4c6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "  0%|          | 0/14844 [01:08<?, ?it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 10000/10000 [00:02<00:00, 4427.22 examples/s]\n",
      "  0%|          | 0/14844 [00:00<?, ?it/s]c:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\trl\\trainer\\utils.py:129: UserWarning: Could not find response key `model:` in the following instance: <bos>user: 그럼 뉴스 보도가 사회에 미치는 긍정적인 영향과 부정적인 영향 중에 어느 쪽이 더 큼?\n",
      " model: 극단적 사건에 대한 뉴스 보도가 사회에 미치는 긍정적인 영향은 부정적인 영향보다 더 큽니다. 이는 뉴스 보도가 사회의 문제를 식별하고 대응하도록 도울 수 있으며, 상황 인식을 높이고 사람들이 스스로를 보호하는 방법을 배우도록 도울 수 있기 때문입니다. 또한, 이러한 보고서는 이러한 사건을 예방하기 위한 조치를 취하도록 도울 수 있습니다. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\trl\\trainer\\utils.py:129: UserWarning: Could not find response key `model:` in the following instance: <bos>user: 그럼 인지 심리학은 어떻게 발전했어?\n",
      " model: 인지 심리학은 비교적 최근에 발전한 학문 분야이지만, 매우 빠르게 성장하고 있습니다. 인지 심리학의 연구 결과는 교육, 임상, 경영 등 다양한 분야에서 응용되고 있으며, 이는 인지 심리학의 중요성과 유용성을 보여줍니다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\trl\\trainer\\utils.py:129: UserWarning: Could not find response key `model:` in the following instance: <bos>user: 기술에 의존하는 것이 항상 좋은 건 아니야?\n",
      " model: 기술에 의존하는 것은 많은 이점을 제공하지만, 인간의 이기심과 탐욕을 증폭시킬 수 있으며, 기술에 대한 과도한 의존은 우리를 자연에서 분리시킬 수 있습니다. 따라서 기술을 현명하게 사용하고 자연과 조화를 이루어 살아가는 것이 중요합니다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\trl\\trainer\\utils.py:129: UserWarning: Could not find response key `model:` in the following instance: <bos>user: 나선형 패턴이 어떻게 사용되는 거야?\n",
      " model: 나선형 패턴은 디자인, 과학을 포함한 다양한 분야에서 다양한 용도로 사용됩니다. 예를 들어, 건축, 예술, 음악과 같은 창의적인 분야에서 종종 사용되며, 과학에서는 데이터를 표시하거나 시각화하는 데 사용됩니다. 이러한 방식으로 나선형 패턴은 우리의 일상 생활을 더욱 편리하고 즐겁게 만들어줍니다. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\trl\\trainer\\utils.py:129: UserWarning: Could not find response key `model:` in the following instance: <bos>user: 그럼 왜 많은 철도 역이 폐쇄되고 사라졌어?\n",
      " model: 철도 역이 폐쇄되고 사라진 이유는 다양합니다. 주요 이유로는 자동차와 항공기의 발달, 도시 계획의 변경, 철도 노선의 변경 등이 있습니다. 이러한 변화들은 철도 역의 중요성을 상쇄시키고, 더 이상 경제적으로 유지할 수 없게 만들었습니다. 또한, 시대의 변화와 함께 사람들의 이동 방식과 취향이 변화하면서 철도 역의 역할이 줄어들었습니다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\trl\\trainer\\utils.py:129: UserWarning: Could not find response key `model:` in the following instance: <bos>user: 음악에서 혁신적인 장르는 뭐가 있어?\n",
      " model: 음악에서 혁신적인 장르로는 블루스에서 힙합까지의 음악 장르의 발전이 있습니다. 블루스는 아프리카계 미국인 노예들의 노래에서 유래한 음악 장르로, 슬픔과 고통을 표현하는 데 사용되었습니다. 이 장르는 시간이 지나면서 재즈, 소울, 록, 힙합 등 다양한 음악 장르로 발전했습니다. 힙합은 1970년대에 뉴욕에서 탄생한 음악 장르로, 랩, 디제잉, 브레이크 댄스 등의 요소로 구성되어 있어 전통적인 음악 장르의 경계를 넘어 새로운 표현 방식을 만들어냈습니다. This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempting to unscale FP16 gradients.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 24\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(  \u001b[38;5;66;03m# Supervised Fine-tuning Trainer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      3\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_subset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m\n\u001b[0;32m     23\u001b[0m )\n\u001b[1;32m---> 24\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:323\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m--> 323\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[1;32mc:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\transformers\\trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\transformers\\trainer.py:2003\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1998\u001b[0m     _grad_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\n\u001b[0;32m   1999\u001b[0m         amp\u001b[38;5;241m.\u001b[39mmaster_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer),\n\u001b[0;32m   2000\u001b[0m         args\u001b[38;5;241m.\u001b[39mmax_grad_norm,\n\u001b[0;32m   2001\u001b[0m     )\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2003\u001b[0m     _grad_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2005\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2006\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2009\u001b[0m     is_accelerate_available()\n\u001b[0;32m   2010\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2011\u001b[0m ):\n\u001b[0;32m   2012\u001b[0m     grad_norm \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_global_grad_norm()\n",
      "File \u001b[1;32mc:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\accelerate\\accelerator.py:2101\u001b[0m, in \u001b[0;36mAccelerator.clip_grad_norm_\u001b[1;34m(self, parameters, max_norm, norm_type)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m   2098\u001b[0m     \u001b[38;5;66;03m# `accelerator.backward(loss)` is doing that automatically. Therefore, its implementation is not needed\u001b[39;00m\n\u001b[0;32m   2099\u001b[0m     \u001b[38;5;66;03m# We cannot return the gradient norm because DeepSpeed does it.\u001b[39;00m\n\u001b[0;32m   2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2101\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munscale_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(parameters, max_norm, norm_type\u001b[38;5;241m=\u001b[39mnorm_type)\n",
      "File \u001b[1;32mc:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\accelerate\\accelerator.py:2064\u001b[0m, in \u001b[0;36mAccelerator.unscale_gradients\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m   2062\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m xm\u001b[38;5;241m.\u001b[39m_fetch_gradients(opt)\n\u001b[0;32m   2063\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(gradients, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_processes)\n\u001b[1;32m-> 2064\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munscale_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:336\u001b[0m, in \u001b[0;36mGradScaler.unscale_\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m    333\u001b[0m inv_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale\u001b[38;5;241m.\u001b[39mdouble()\u001b[38;5;241m.\u001b[39mreciprocal()\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    334\u001b[0m found_inf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((), \u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 336\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unscale_grads_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    338\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mUNSCALED\n",
      "File \u001b[1;32mc:\\Users\\hyun0\\anaconda3\\envs\\kdb3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:258\u001b[0m, in \u001b[0;36mGradScaler._unscale_grads_\u001b[1;34m(self, optimizer, inv_scale, found_inf, allow_fp16)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m allow_fp16) \u001b[38;5;129;01mand\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to unscale FP16 gradients.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mis_sparse:\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# is_coalesced() == False means the sparse grad has values with duplicate indices.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# coalesce() deduplicates indices and adds all values that have the same index.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# For scaled fp16 values, there's a good chance coalescing will cause overflow,\u001b[39;00m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# so we should check the coalesced _values().\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfloat16:\n",
      "\u001b[1;31mValueError\u001b[0m: Attempting to unscale FP16 gradients."
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(  # Supervised Fine-tuning Trainer\n",
    "    model=model,\n",
    "    train_dataset=train_subset,\n",
    "    args=transformers.TrainingArguments( \n",
    "        output_dir=new_model,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        #warmup_steps=2,\n",
    "        warmup_ratio=0.03,\n",
    "        num_train_epochs=3,\n",
    "        #max_steps=10,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        report_to=\"wandb\",\n",
    "        \n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=formatting_func,\n",
    "    data_collator=collator,\n",
    "    max_seq_length=2048\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5Mim0lNViwe",
    "outputId": "4534ee26-63e3-4ced-ee27-673f0b9d7afb"
   },
   "outputs": [],
   "source": [
    "text = 'user : 전문적인 관점에서 소셜 미디어를 어떻게 활용해야 해? model :'\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'user', 'value': '대학 입학 단계에서 의사소통 기회가 뭐야?'},\n",
       " {'from': 'gpt',\n",
       "  'value': '대학 입학 단계에서의 의사소통 기회는 대학과 연결하고 다양한 수준의 학업과 교육 활동에 참여하기 위해 제공되는 기회를 말합니다. 이는 대학에 입학하고 처음 대학 생활을 시작할 때 학생들이 대학 내에서 자신을 표현하고 다른 사람들과 소통하는 기회를 제공합니다.'},\n",
       " {'from': 'user', 'value': '그럼 이런 의사소통 기회를 잘 활용하려면 어떻게 해야 해?'},\n",
       " {'from': 'gpt',\n",
       "  'value': '이런 의사소통 기회를 잘 활용하기 위해서는 몇 가지 전략을 따르는 것이 좋습니다. 첫째, 강력하고 생산적인 관계를 형성하기 위해 대학 내에서 다양한 사람들과 교류하고 소통하는 것이 중요합니다. 둘째, 성공적인 대인관계를 위해서는 피드백을 제공하고 수락하는 것이 중요합니다. 이를 통해 서로의 의견을 이해하고 존중하며, 더 나은 관계를 형성할 수 있습니다.'},\n",
       " {'from': 'user', 'value': '전문적인 관점에서 소셜 미디어를 어떻게 활용해야 해?'},\n",
       " {'from': 'gpt',\n",
       "  'value': '전문적인 관점에서 소셜 미디어를 활용하기 위해서는 몇 가지 팁을 따르는 것이 좋습니다. 첫째, 자신의 전문적인 입장을 강화하기 위해 소셜 미디어를 적절히 사용하는 것이 중요합니다. 이는 자신의 전문 분야에 관련된 정보를 공유하고, 전문적인 토론에 참여하는 것을 의미합니다. 둘째, 소셜 미디어를 통해 학업, 교외 활동 및 일자리 기회를 탐색하는 데 도움이 되는 정보를 찾아보는 것도 유용합니다. 이를 통해 자신의 경력 발전에 도움이 될 수 있는 기회를 발견할 수 있습니다.'},\n",
       " {'from': 'user', 'value': '서면 의사소통의 중요성은 구체적으로 뭐야?'},\n",
       " {'from': 'gpt',\n",
       "  'value': '서면 의사소통의 중요성은 다양한 서신 및 문서를 만들고 수정하는 데 적절한 문법과 스타일을 활용하는 것에 있습니다. 이는 교과 과제, 논문, 책임 서류, 편지 등을 작성할 때 중요한 역할을 합니다. 서면 의사소통을 잘 하는 것은 커뮤니케이션 능력을 향상시키고, 다양한 상황에서 명확하고 효과적으로 메시지를 전달하는 데 도움이 됩니다. 이는 학업 성공뿐만 아니라 장기적인 경력 발전에도 중요한 요소입니다.'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['conversations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user : 전문적인 관점에서 소셜 미디어를 어떻게 활용해야 해? model : 전문적인 관점에서 소셜 미디어를 활용하기 위해서는 소셜 미디어의 \n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**inputs, max_new_tokens=512)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "djg3QAMuVx8R"
   },
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sw_innov01/anaconda3/envs/gemma/lib/python3.11/site-packages/transformers/utils/hub.py:834: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/sw_innov01/anaconda3/envs/gemma/lib/python3.11/site-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████████████████████████| 100M/100M [00:21<00:00, 4.67MB/s]\n",
      "/home/sw_innov01/anaconda3/envs/gemma/lib/python3.11/site-packages/transformers/utils/hub.py:834: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "tokenizer.json: 100%|███████████████████████████████████████| 17.5M/17.5M [00:03<00:00, 4.88MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Coldbrew9/Fine-tuning-gemma-doubleQ_v5_10Ep/commit/819e49bfe0d45ed2925693e28ee933bc7a601bc4', commit_message='Upload tokenizer', commit_description='', oid='819e49bfe0d45ed2925693e28ee933bc7a601bc4', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HUGGINGFACE_AUTH_TOKEN = '**'\n",
    "MODEL_SAVE_HUB_PATH = f'Coldbrew9/Fine tuning gemma singleQ'\n",
    "trainer.model.push_to_hub(\n",
    "\t\t\tMODEL_SAVE_HUB_PATH, \n",
    "\t\t\tuse_temp_dir=True, \n",
    "\t\t\tuse_auth_token=HUGGINGFACE_AUTH_TOKEN\n",
    ")\n",
    "trainer.tokenizer.push_to_hub(\n",
    "\t\t\tMODEL_SAVE_HUB_PATH, \n",
    "\t\t\tuse_temp_dir=True, \n",
    "\t\t\tuse_auth_token=HUGGINGFACE_AUTH_TOKEN\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02b296efbff143f4bfbb904cbc7b1109": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "320fa615d4de4652ac34fc2518f7749e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "32e7669cd82042cbbb419e25db606c1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b6698be32bf74c4087e129fab6e13fdd",
       "IPY_MODEL_ff7333b35c1c472482df6550f6e43be2",
       "IPY_MODEL_da4df56a1ba440dbb69087d0019cab1d"
      ],
      "layout": "IPY_MODEL_ad598693c58549e0a83a1328d77b8f83"
     }
    },
    "3f33eabd6f7f46ef8138abe748d8fbb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72ac83e43e2b4d4498070a5b701a5572": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75280ef205a245be92da268e0752dc71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad598693c58549e0a83a1328d77b8f83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6698be32bf74c4087e129fab6e13fdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de2f7a60851f4681877a4c8dccba29cc",
      "placeholder": "​",
      "style": "IPY_MODEL_02b296efbff143f4bfbb904cbc7b1109",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "da4df56a1ba440dbb69087d0019cab1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75280ef205a245be92da268e0752dc71",
      "placeholder": "​",
      "style": "IPY_MODEL_3f33eabd6f7f46ef8138abe748d8fbb1",
      "value": " 3/3 [01:06&lt;00:00, 18.14s/it]"
     }
    },
    "de2f7a60851f4681877a4c8dccba29cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff7333b35c1c472482df6550f6e43be2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72ac83e43e2b4d4498070a5b701a5572",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_320fa615d4de4652ac34fc2518f7749e",
      "value": 3
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
